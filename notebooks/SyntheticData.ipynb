{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os import path\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../utils\"))\n",
    "sys.path.append(os.path.abspath(\"../models\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from simple_nn_lightning import *\n",
    "from model_utils import *\n",
    "from simple_nn_utils import *\n",
    "\n",
    "\n",
    "import wandb\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "from pl_bolts.callbacks import TrainingDataMonitor\n",
    "\n",
    "from torch.optim.lr_scheduler import MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 20\n",
    "N_CLASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data, fake_targets = make_multilabel_classification(\n",
    "    n_samples=100,\n",
    "    n_features=INPUT_DIM,\n",
    "    n_classes=N_CLASSES,\n",
    "    allow_unlabeled=False,\n",
    "    random_state=314,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = range(fake_data.shape[0])\n",
    "X_train, X_test, y_train, y_test, idxs_train, idxs_test = train_test_split(\n",
    "    fake_data,\n",
    "    fake_targets,\n",
    "    indices,\n",
    "    #                                                     stratify=train_test_stratify, # don't know how this works with multilabel\n",
    "    test_size=0.2,\n",
    "    random_state=314,\n",
    ")\n",
    "# X_train = torch.tensor([[1,3,5],[50,100,10]])\n",
    "# y_train = torch.tensor([[0,1],[1,1]])\n",
    "# X_test = torch.tensor([[1,3,5],[50,100,10]])\n",
    "# y_test = torch.tensor([[0,1],[1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 4., 1., ..., 1., 2., 0.],\n",
       "        [2., 2., 0., ..., 0., 1., 2.],\n",
       "        [3., 3., 1., ..., 6., 3., 3.],\n",
       "        ...,\n",
       "        [4., 6., 5., ..., 0., 3., 0.],\n",
       "        [4., 5., 4., ..., 0., 0., 3.],\n",
       "        [4., 2., 4., ..., 0., 1., 1.]]),\n",
       " array([[ 5.,  3.,  3.,  4.,  3.,  5.,  2.,  5.,  4.,  4.,  0.,  1.,  1.,\n",
       "          3.,  3.,  1.,  4.,  0.,  3.,  0.],\n",
       "        [ 2.,  2.,  1.,  3.,  0.,  2.,  0.,  3.,  3.,  2.,  1.,  3.,  4.,\n",
       "          5.,  2.,  4.,  3.,  2.,  2.,  2.],\n",
       "        [ 1.,  4.,  2.,  4.,  0.,  1.,  2.,  3.,  3.,  1.,  2.,  0.,  7.,\n",
       "          1.,  2.,  4.,  3.,  1.,  3.,  1.],\n",
       "        [ 1.,  3.,  5.,  4.,  0.,  0.,  5.,  2.,  1.,  3.,  2.,  0.,  2.,\n",
       "          3.,  3.,  4.,  3.,  2.,  3.,  3.],\n",
       "        [ 3.,  2.,  5.,  0.,  4.,  4.,  4.,  1.,  1.,  5.,  4.,  1.,  1.,\n",
       "         11.,  2.,  1.,  4.,  1.,  5.,  1.],\n",
       "        [ 3.,  3.,  1.,  6.,  2.,  2.,  2.,  1.,  2.,  2.,  3.,  1.,  3.,\n",
       "          4.,  1.,  1.,  2.,  3.,  1.,  5.],\n",
       "        [ 3.,  1.,  3.,  1.,  4.,  0.,  3.,  3.,  0.,  0.,  2.,  1.,  3.,\n",
       "          2.,  2.,  4.,  3.,  1.,  1.,  2.],\n",
       "        [ 2.,  7.,  5.,  4.,  1.,  0.,  4.,  5.,  2.,  0.,  2.,  0.,  5.,\n",
       "          1.,  3.,  6.,  2.,  0., 10.,  0.],\n",
       "        [ 0.,  4.,  2.,  0.,  2.,  2.,  3.,  1.,  6.,  2.,  2.,  0.,  7.,\n",
       "          1.,  4.,  5.,  2.,  2.,  0.,  2.],\n",
       "        [ 1.,  1.,  5.,  2.,  3.,  1.,  1.,  0.,  0.,  5.,  3.,  1.,  0.,\n",
       "          5.,  0.,  7.,  3.,  0.,  2.,  2.],\n",
       "        [ 5.,  2.,  0.,  2.,  2.,  3.,  2.,  1.,  3.,  2.,  4.,  0.,  1.,\n",
       "          6.,  1.,  2.,  5.,  2.,  3.,  3.],\n",
       "        [ 3.,  1.,  1.,  3.,  0.,  3.,  6.,  2.,  2.,  5.,  1.,  0.,  0.,\n",
       "          6.,  4.,  2.,  3.,  0.,  1.,  1.],\n",
       "        [ 4.,  2.,  3.,  3.,  3.,  2.,  4.,  1.,  4.,  2.,  2.,  1.,  4.,\n",
       "          4.,  3.,  2.,  3.,  0.,  1.,  3.],\n",
       "        [ 0.,  2.,  3.,  6.,  0.,  3.,  6.,  1.,  2.,  2.,  4.,  0.,  3.,\n",
       "          9.,  3.,  7.,  1.,  2.,  3.,  3.],\n",
       "        [ 1.,  3.,  0.,  3.,  4.,  2.,  1.,  4.,  1.,  2.,  4.,  0.,  5.,\n",
       "          6.,  3.,  4., 12.,  5.,  2.,  2.],\n",
       "        [ 2.,  3.,  1.,  3.,  2.,  1.,  3.,  0.,  4.,  0.,  6.,  2.,  2.,\n",
       "         10.,  2.,  1.,  0.,  5.,  3.,  1.],\n",
       "        [ 3.,  1.,  3.,  4.,  0.,  1.,  4.,  1.,  2.,  2.,  1.,  0.,  6.,\n",
       "          1.,  5.,  7.,  4.,  1.,  3.,  1.],\n",
       "        [ 5.,  2.,  2.,  0.,  1.,  4.,  3.,  0.,  3.,  2.,  3.,  3.,  1.,\n",
       "          9.,  2.,  3.,  2.,  5.,  2.,  5.],\n",
       "        [ 4.,  4.,  2.,  2.,  2.,  2.,  1.,  1.,  7.,  1.,  3.,  0.,  3.,\n",
       "          3.,  3.,  3.,  3.,  1.,  2.,  1.],\n",
       "        [ 6.,  0.,  2.,  3.,  3.,  5.,  0.,  3.,  2.,  3.,  7.,  3.,  3.,\n",
       "          3.,  0.,  2.,  2.,  2.,  6.,  3.]]),\n",
       " array([[0, 1, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 1, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [1, 0, 1, 0, 1],\n",
       "        [0, 1, 0, 1, 1],\n",
       "        [1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 1, 1],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 1, 1],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 0, 1],\n",
       "        [1, 1, 0, 0, 0],\n",
       "        [0, 0, 1, 1, 1],\n",
       "        [1, 0, 1, 0, 0],\n",
       "        [1, 0, 1, 0, 1],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [1, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 1],\n",
       "        [1, 1, 0, 1, 1],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [1, 1, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 1],\n",
       "        [0, 0, 0, 1, 1],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 1, 0],\n",
       "        [1, 1, 0, 1, 0],\n",
       "        [1, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 1, 0],\n",
       "        [1, 0, 1, 1, 1],\n",
       "        [0, 1, 0, 1, 1],\n",
       "        [1, 0, 0, 1, 1],\n",
       "        [1, 1, 0, 1, 0],\n",
       "        [1, 0, 0, 0, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 0, 1, 1, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [1, 1, 0, 1, 0],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 0, 0, 0, 1],\n",
       "        [0, 1, 0, 0, 1],\n",
       "        [1, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [1, 1, 0, 1, 1],\n",
       "        [0, 1, 0, 1, 1],\n",
       "        [0, 0, 1, 0, 0],\n",
       "        [0, 1, 1, 1, 1],\n",
       "        [1, 1, 0, 1, 1],\n",
       "        [1, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 1, 0],\n",
       "        [0, 0, 0, 0, 1],\n",
       "        [0, 1, 0, 1, 1],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 1],\n",
       "        [0, 0, 0, 1, 1]]),\n",
       " array([[0, 1, 0, 1, 1],\n",
       "        [1, 0, 0, 1, 1],\n",
       "        [1, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 1],\n",
       "        [0, 0, 1, 1, 0],\n",
       "        [1, 0, 0, 0, 1],\n",
       "        [1, 0, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 1, 1],\n",
       "        [0, 0, 1, 0, 0],\n",
       "        [1, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [1, 1, 0, 1, 1],\n",
       "        [0, 0, 0, 1, 1],\n",
       "        [1, 1, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 1],\n",
       "        [1, 0, 1, 1, 0],\n",
       "        [1, 0, 0, 0, 1],\n",
       "        [1, 1, 1, 1, 1]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to store this value for the NN model definition\n",
    "INPUT_DIM = X_train.shape[1]\n",
    "N_CLASSES = y_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(X_train).float(), torch.tensor(y_train).float()\n",
    ")\n",
    "val_dataset = TensorDataset(torch.tensor(X_test).float(), torch.tensor(y_test).float())\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=5,\n",
    "    #  collate_fn=collate_wrapper,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=5,\n",
    "    #  collate_fn=collate_wrapper,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvsocrates\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/decile/test-project/runs/3adn87ki\" target=\"_blank\">solar-paper-60</a></strong> to <a href=\"https://wandb.ai/decile/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config_fp = f\"/home/vs428/Documents/deep-ed-diags/configs/dev_test_config.yaml\"\n",
    "\n",
    "fast_dev_run = False\n",
    "# impacts how quickly we do earlystopping too by patience\n",
    "eval_freq = 2\n",
    "\n",
    "wandb.init(project=\"test-project\", \n",
    "           entity=\"decile\",\n",
    "           config=config_fp, \n",
    "           allow_val_change=True,\n",
    "           save_code=True)\n",
    "\n",
    "WANDB_RUN_NAME = wandb.run.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# just fix some issue of conditional params\n",
    "if wandb.config['loss_fn'] == \"focal\":\n",
    "    wandb.config.update({'class_weight_type': None})\n",
    "if fast_dev_run:\n",
    "    wandb.config.update({'drop_sparse_cols': 0}, allow_val_change=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LitAbdPainPredictionMLP(\n",
      "  (fc1): Linear(in_features=20, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (fc4): Linear(in_features=16, out_features=5, bias=True)\n",
      "  (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (loss): MultilabelFocalLoss()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name    | Type                | Params\n",
      "------------------------------------------------\n",
      "0 | fc1     | Linear              | 336   \n",
      "1 | fc2     | Linear              | 272   \n",
      "2 | fc4     | Linear              | 85    \n",
      "3 | bn1     | BatchNorm1d         | 32    \n",
      "4 | bn2     | BatchNorm1d         | 32    \n",
      "5 | dropout | Dropout             | 0     \n",
      "6 | loss    | MultilabelFocalLoss | 0     \n",
      "------------------------------------------------\n",
      "757       Trainable params\n",
      "0         Non-trainable params\n",
      "757       Total params\n",
      "0.003     Total estimated model params size (MB)\n",
      "/gpfs/milgram/project/rtaylor/vs428/conda_envs/factcheck_env/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /gpfs/milgram/project/rtaylor/shared/ABDPain_EarlyDiags/models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed874eb7d526488fba61114a276072da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  tensor(0.3528, device='cuda:0')\n",
      "mean:  tensor(0.3479, device='cuda:0')\n",
      "Validation Precision/macro: 0.5454545617103577\n",
      "Validation Recall/macro: 0.6000000238418579\n",
      "Training is started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/milgram/project/rtaylor/vs428/conda_envs/factcheck_env/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "/gpfs/milgram/project/rtaylor/vs428/conda_envs/factcheck_env/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "/gpfs/milgram/project/rtaylor/vs428/conda_envs/factcheck_env/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:433: UserWarning: The number of training samples (16) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414cd6a961584c67a1ad5d0bbcca8a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/milgram/project/rtaylor/vs428/conda_envs/factcheck_env/lib/python3.7/site-packages/pytorch_lightning/loggers/wandb.py:342: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  \"There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  tensor(0.4170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "# correct?:\n",
      " tensor(13, device='cuda:0')\n",
      "tensor(2.0848, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "mean:  tensor(0.4294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.3980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.3517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.3532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.3739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.3268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.3119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.3910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.3212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.3360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.3503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.3552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.3069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "# correct?:\n",
      " tensor(20, device='cuda:0')\n",
      "tensor(1.3281, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "mean:  tensor(0.2692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.3191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.3001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.3763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.3045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2307, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098cb61748ac45e8b217b5837c7d0f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric validation_loss improved. New best score: 1.511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  tensor(0.2646, device='cuda:0')\n",
      "mean:  tensor(0.3858, device='cuda:0')\n",
      "mean:  tensor(0.2809, device='cuda:0')\n",
      "mean:  tensor(0.2774, device='cuda:0')\n",
      "Validation Precision/macro: 0.75\n",
      "Validation Recall/macro: 0.6000000238418579\n",
      "mean:  tensor(0.2254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "# correct?:\n",
      " tensor(21, device='cuda:0')\n",
      "tensor(1.1270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "mean:  tensor(0.2204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "# correct?:\n",
      " tensor(22, device='cuda:0')\n",
      "tensor(1.0429, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "mean:  tensor(0.1917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2316, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9d214cde57444b8a4b149e36f47c726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric validation_loss improved by 0.176 >= min_delta = 1e-05. New best score: 1.335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  tensor(0.2210, device='cuda:0')\n",
      "mean:  tensor(0.4045, device='cuda:0')\n",
      "mean:  tensor(0.1785, device='cuda:0')\n",
      "mean:  tensor(0.2638, device='cuda:0')\n",
      "Validation Precision/macro: 0.7272727489471436\n",
      "Validation Recall/macro: 0.800000011920929\n",
      "mean:  tensor(0.1863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "# correct?:\n",
      " tensor(20, device='cuda:0')\n",
      "tensor(0.9314, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "mean:  tensor(0.1749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "# correct?:\n",
      " tensor(22, device='cuda:0')\n",
      "tensor(0.8401, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "mean:  tensor(0.1529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1820, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f4ad630976474fb4de9762fe9460bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  tensor(0.2055, device='cuda:0')\n",
      "mean:  tensor(0.3835, device='cuda:0')\n",
      "mean:  tensor(0.1917, device='cuda:0')\n",
      "mean:  tensor(0.2940, device='cuda:0')\n",
      "Validation Precision/macro: 0.7272727489471436\n",
      "Validation Recall/macro: 0.800000011920929\n",
      "mean:  tensor(0.1556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "# correct?:\n",
      " tensor(22, device='cuda:0')\n",
      "tensor(0.7779, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "mean:  tensor(0.1602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.0955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "# correct?:\n",
      " tensor(22, device='cuda:0')\n",
      "tensor(0.7681, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "mean:  tensor(0.1287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.2183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "mean:  tensor(0.1612, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feff4fc90ae548a4b9d885c88a6815b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric validation_loss did not improve in the last 2 records. Best score: 1.335. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  tensor(0.1897, device='cuda:0')\n",
      "mean:  tensor(0.4541, device='cuda:0')\n",
      "mean:  tensor(0.2178, device='cuda:0')\n",
      "mean:  tensor(0.3142, device='cuda:0')\n",
      "Validation Precision/macro: 0.800000011920929\n",
      "Validation Recall/macro: 0.800000011920929\n",
      "Training is done.\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "# log the histograms of input data sent to LightningModule.training_step\n",
    "training_data_monitor = TrainingDataMonitor(log_every_n_steps=25)\n",
    "print_callback = PrintCallback()\n",
    "\n",
    "early_stopping = EarlyStopping(min_delta=0.00001, patience=2, verbose=True, monitor=\"validation_loss\")\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=\"/gpfs/milgram/project/rtaylor/shared/ABDPain_EarlyDiags/models\",\n",
    "                                      filename=f\"{WANDB_RUN_NAME}.model\",\n",
    "                                      monitor=\"validation_loss\")\n",
    "\n",
    "# Predict after trainer callback using 20% of the validation dataset\n",
    "after_train_dataset = val_dataset[np.random.choice(len(val_dataset), int(len(val_dataset)*0.2), replace=False)]\n",
    "val_preds_logger = PredictionLogger(after_train_dataset)\n",
    "\n",
    "callbacks = [lr_monitor, training_data_monitor, print_callback, early_stopping, checkpoint_callback, val_preds_logger]\n",
    "\n",
    "# Logger\n",
    "wandb_logger = WandbLogger(project=\"test-project\")    \n",
    "\n",
    "trainer = Trainer(logger=wandb_logger,\n",
    "                 callbacks=callbacks,\n",
    "                 check_val_every_n_epoch=eval_freq,\n",
    "                 devices=\"auto\", accelerator=\"auto\",\n",
    "                  fast_dev_run=fast_dev_run\n",
    "                 )\n",
    "\n",
    "\n",
    "if wandb.config['loss_fn'] == \"focal\":\n",
    "    loss = MultilabelFocalLoss(N_CLASSES, gamma=wandb.config[\"focal_loss_gamma\"])\n",
    "elif wandb.config['loss_fn'] == \"bce\":\n",
    "    loss = torch.nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
    "else:\n",
    "    loss = torch.nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
    "\n",
    "\n",
    "mlp_system = LitAbdPainPredictionMLP(\n",
    "    INPUT_DIM,\n",
    "    N_CLASSES,\n",
    "    config=wandb.config,\n",
    "    loss_fn=loss,\n",
    "    layer_size=wandb.config[\"layer_size\"],\n",
    "    dropout=wandb.config[\"dropout\"],\n",
    ")\n",
    "\n",
    "print(mlp_system, flush=True)\n",
    "\n",
    "trainer.fit(mlp_system, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing seems to work on a synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
